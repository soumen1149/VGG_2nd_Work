{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539d5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190f1a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65a8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MudraDataset(Dataset):\n",
    "    def __init__(self, root_dir, state='All', transform=None):\n",
    "        #\"\"\"\n",
    "        #Args:\n",
    "            #csv_files (string): Path to the csv file with annotations\n",
    "            #root_dir (string): Directory with all the images\n",
    "            #transform (callable, optional): Optional transform to be applied on a sample\n",
    "        #\"\"\"\n",
    "        #self.mudraJoints = pd.read_csv(csv_file)\n",
    "        self.state = state\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.X_data = []\n",
    "        self.Y_data = []\n",
    "        \n",
    "        if os.path.isdir(root_dir):\n",
    "            for dirs in os.listdir(root_dir):\n",
    "                #print(dirs)\n",
    "                full_path = os.path.join(root_dir, dirs)\n",
    "                csv_path = os.path.join(full_path, 'Annotation.csv')\n",
    "                csv_file = pd.read_csv(csv_path)\n",
    "                for i, row in csv_file.iterrows():\n",
    "                    rlen = len(row)\n",
    "                    img_path = os.path.join(full_path, row[0])\n",
    "                    #print(img_path)\n",
    "                    image = img_path\n",
    "                    self.X_data.append(image)\n",
    "                    jointAngle = row[1:rlen-1]\n",
    "                    \n",
    "                    jointAngle = np.array([jointAngle])\n",
    "                    jointAngle = jointAngle.astype('float')\n",
    "                    self.Y_data.append(jointAngle)\n",
    "                    #sample = {'image': image, 'jointAngle': jointAngle}\n",
    "                    #self.data.append(sample)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(self.X_data,\n",
    "                                                self.Y_data, test_size=0.25, random_state=42)\n",
    "        if state == 'Train':    \n",
    "            self.X_data, self.Y_data = X_train, Y_train\n",
    "        elif state == 'Test':\n",
    "            self.X_data, self.Y_data = X_test, Y_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        #img_name = os.path.join(self.root_dir, self.mudraJoints.iloc[idx, 0])\n",
    "        #image = cv2.imread(img_name)\n",
    "        #jointCood = self.mudraJoints.iloc[idx, 1:]\n",
    "        #jointCood = np.array([jointCood])\n",
    "        #jointCood = jointCood.astype('float')#.reshape(-1,2)\n",
    "        #print(self.X_data[i])\n",
    "        #print(self.X_data[idx])\n",
    "        sample = {'image': cv2.imread(self.X_data[idx]).astype('float'), 'label': self.Y_data[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6388a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TouchDataset(Dataset):\n",
    "    def __init__(self, root_dir, num_classes, state='All', transform=None):\n",
    "        #\"\"\"\n",
    "        #Args:\n",
    "            #csv_files (string): Path to the csv file with annotations\n",
    "            #root_dir (string): Directory with all the images\n",
    "            #transform (callable, optional): Optional transform to be applied on a sample\n",
    "        #\"\"\"\n",
    "        #self.mudraJoints = pd.read_csv(csv_file)\n",
    "        self.state = state\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.X_data = []\n",
    "        self.Y_data = []\n",
    "        #self.Z_data = []\n",
    "        self.pos = np.zeros(num_classes)\n",
    "        self.total = 0\n",
    "        \n",
    "        \n",
    "        if os.path.isdir(root_dir):\n",
    "            for dirs in os.listdir(root_dir):\n",
    "                #print(dirs)\n",
    "                full_path = os.path.join(root_dir, dirs)\n",
    "                csv_path = os.path.join(full_path, 'Annotation.csv')\n",
    "                csv_file = pd.read_csv(csv_path)\n",
    "                for i, row in csv_file.iterrows():\n",
    "                    labels = np.zeros(num_classes)\n",
    "                    rlen = len(row)\n",
    "                    img_path = os.path.join(full_path, row[0])\n",
    "                    #print(img_path)\n",
    "                    image = img_path\n",
    "                    self.X_data.append(image)\n",
    "                    touchVal = row[-1]\n",
    "                    #print(touchVal)\n",
    "                    touchVal = touchVal[1:-1]\n",
    "                    #print(touchVal)\n",
    "                    touchLabel = touchVal.split(\",\")\n",
    "                    for s in range(len(touchLabel)):\n",
    "                        #print(touchLabel[s])\n",
    "                        labels[int(touchLabel[s])] = 1\n",
    "                        self.pos[int(touchLabel[s])] += 1\n",
    "                        \n",
    "                    #labels = np.array([jointAngle])\n",
    "                    labels = labels.astype('float')\n",
    "                    self.Y_data.append(labels)\n",
    "                    #self.Z_data.append(row[0])\n",
    "                    self.total += 1\n",
    "                    #sample = {'image': image, 'jointAngle': jointAngle}\n",
    "                    #self.data.append(sample)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(self.X_data,\n",
    "                                                self.Y_data, test_size=0.25, random_state=42)\n",
    "        if state == 'Train':    \n",
    "            self.X_data, self.Y_data = X_train, Y_train\n",
    "        elif state == 'Test':\n",
    "            self.X_data, self.Y_data = X_test, Y_test\n",
    "        #print(self.Y_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        #img_name = os.path.join(self.root_dir, self.mudraJoints.iloc[idx, 0])\n",
    "        #image = cv2.imread(img_name)\n",
    "        #jointCood = self.mudraJoints.iloc[idx, 1:]\n",
    "        #jointCood = np.array([jointCood])\n",
    "        #jointCood = jointCood.astype('float')#.reshape(-1,2)\n",
    "        #print(self.X_data[i])\n",
    "        #print(self.X_data[idx])\n",
    "        sample = {'image': cv2.imread(self.X_data[idx]).astype('float'), 'label': self.Y_data[idx], 'name': self.X_data[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052da9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing Rescale, RandomCrop, and ToTensor\n",
    "class Rescale(object):\n",
    "    #Args:\n",
    "    #output_size (tuple or int): Desired output size. If tuple, output is matched to output size. It int, smaller of\n",
    "    #image edges is matched to output_size keeping aspect ratio the same\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, joints, name = sample['image'], sample['label'], sample['name']\n",
    "        #print(image)\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        \n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        return {'image': img, 'label': joints, 'name': name}\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    #Args:\n",
    "    #output_size (tuple or int): Desired output size. If int, square crop is made\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (tuple, int))\n",
    "\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, joints = sample['image'], sample['label']\n",
    "        #print(image)\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h, left: left + new_w]\n",
    "\n",
    "        return {'image': image, 'label': joints}\n",
    "\n",
    "class ToTensor(object):\n",
    "    #Convert numpy array image to tensor image\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, joints, name = sample['image'], sample['label'], sample['name']\n",
    "\n",
    "        #swap color axis because\n",
    "        #numpy image: H * W * C\n",
    "        #torch image: C * H * W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image).to(torch.float), 'label': torch.from_numpy(joints).to(torch.float), 'name': name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a01c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(dataset, batch_size, random_seed=42, valid_size=0.1, shuffle=True, test=False):\n",
    "    num_train = len(dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    \n",
    "    if test:\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        return (train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d837184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13908\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TouchDataset(root_dir='Mudra Dataset/Single hand', num_classes=160,\n",
    "                                  transform=transforms.Compose([Rescale((227,227)), ToTensor()]))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12137d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584f9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36839d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
