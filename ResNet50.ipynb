{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df1c8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import cv2\n",
    "from skimage import transform\n",
    "from torchsummary import summary\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa303f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e940b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "print(a/np.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c63920b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MudraDataset(Dataset):\n",
    "    def __init__(self, root_dir, state='All', transform=None):\n",
    "        #\"\"\"\n",
    "        #Args:\n",
    "            #csv_files (string): Path to the csv file with annotations\n",
    "            #root_dir (string): Directory with all the images\n",
    "            #transform (callable, optional): Optional transform to be applied on a sample\n",
    "        #\"\"\"\n",
    "        #self.mudraJoints = pd.read_csv(csv_file)\n",
    "        self.state = state\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.X_data = []\n",
    "        self.Y_data = []\n",
    "        \n",
    "        if os.path.isdir(root_dir):\n",
    "            for dirs in os.listdir(root_dir):\n",
    "                #print(dirs)\n",
    "                full_path = os.path.join(root_dir, dirs)\n",
    "                csv_path = os.path.join(full_path, 'Annotation.csv')\n",
    "                csv_file = pd.read_csv(csv_path)\n",
    "                for i, row in csv_file.iterrows():\n",
    "                    img_path = os.path.join(full_path, row[0])\n",
    "                    #print(img_path)\n",
    "                    image = img_path\n",
    "                    self.X_data.append(image)\n",
    "                    jointAngle = row[1:]\n",
    "                    jointAngle = np.array([jointAngle])\n",
    "                    maxval = np.max(jointAngle)\n",
    "                    if maxval>0:\n",
    "                        jointAngle = jointAngle/np.max(jointAngle)\n",
    "                    jointAngle = jointAngle.astype('float')\n",
    "                    self.Y_data.append(jointAngle)\n",
    "                    #sample = {'image': image, 'jointAngle': jointAngle}\n",
    "                    #self.data.append(sample)\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(self.X_data,\n",
    "                                                self.Y_data, test_size=0.25, random_state=42)\n",
    "        if state == 'Train':    \n",
    "            self.X_data, self.Y_data = X_train, Y_train\n",
    "        elif state == 'Test':\n",
    "            self.X_data, self.Y_data = X_test, Y_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample = {'image': cv2.imread(self.X_data[idx]).astype('float'), 'jointCood': self.Y_data[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c84dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing Rescale, RandomCrop, and ToTensor\n",
    "class Rescale(object):\n",
    "    #Args:\n",
    "    #output_size (tuple or int): Desired output size. If tuple, output is matched to output size. It int, smaller of\n",
    "    #image edges is matched to output_size keeping aspect ratio the same\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, joints = sample['image'], sample['jointCood']\n",
    "        #print(image)\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        \n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        return {'image': img, 'jointCood': joints}\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    #Args:\n",
    "    #output_size (tuple or int): Desired output size. If int, square crop is made\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (tuple, int))\n",
    "\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, joints = sample['image'], sample['jointCood']\n",
    "        #print(image)\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h, left: left + new_w]\n",
    "\n",
    "        return {'image': image, 'jointCood': joints}\n",
    "\n",
    "class ToTensor(object):\n",
    "    #Convert numpy array image to tensor image\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, joints = sample['image'], sample['jointCood']\n",
    "\n",
    "        #swap color axis because\n",
    "        #numpy image: H * W * C\n",
    "        #torch image: C * H * W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image).to(torch.float), 'jointCood': torch.from_numpy(joints).to(torch.float)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82670d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MudraDataset(root_dir='Mudra Dataset/Single hand', state='Train',\n",
    "                                  transform=transforms.Compose([Rescale((224,224)), ToTensor()]))\n",
    "\n",
    "test_dataset = MudraDataset(root_dir='Mudra Dataset/Single hand', state='Test',\n",
    "                                  transform=transforms.Compose([Rescale((224,224)), ToTensor()]))\n",
    "\n",
    "val_dataset = MudraDataset(root_dir='Mudra Dataset/Single hand', state='Train',\n",
    "                                  transform=transforms.Compose([Rescale((224,224)), ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "574402e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(batch_size, random_seed=42, valid_size=0.1, shuffle=True, test=False):\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    \n",
    "    if test:\n",
    "        return torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        return (train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0aa494ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = data_loader(batch_size=16)\n",
    "test_loader = data_loader(batch_size=16, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c26f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d015179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c592969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer0): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = 14\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "learning_rate = 0.00001\n",
    "\n",
    "model = ResNet(ResidualBlock, [3,4,6,3], num_classes=num_classes).to(device)\n",
    "print(model)\n",
    "\n",
    "#Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay=0.001, momentum=0.9)\n",
    "\n",
    "#Train the model\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9911c5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumen/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([16, 1, 14])) that is different to the input size (torch.Size([16, 14])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/soumen/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([12, 1, 14])) that is different to the input size (torch.Size([12, 14])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train loss: 0.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soumen/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([3, 1, 14])) that is different to the input size (torch.Size([3, 14])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1978\n",
      "Epoch [2/50], Train loss: 0.1942\n",
      "Validation loss: 0.1946\n",
      "Epoch [3/50], Train loss: 0.1922\n",
      "Validation loss: 0.1985\n",
      "Epoch [4/50], Train loss: 0.1911\n",
      "Validation loss: 0.1962\n",
      "Epoch [5/50], Train loss: 0.1907\n",
      "Validation loss: 0.1951\n",
      "Epoch [6/50], Train loss: 0.1902\n",
      "Validation loss: 0.1942\n",
      "Epoch [7/50], Train loss: 0.1896\n",
      "Validation loss: 0.1927\n",
      "Epoch [8/50], Train loss: 0.1894\n",
      "Validation loss: 0.1939\n",
      "Epoch [9/50], Train loss: 0.1895\n",
      "Validation loss: 0.1951\n",
      "Epoch [10/50], Train loss: 0.1890\n",
      "Validation loss: 0.1983\n",
      "Epoch [11/50], Train loss: 0.1893\n",
      "Validation loss: 0.1940\n",
      "Epoch [12/50], Train loss: 0.1894\n",
      "Validation loss: 0.1930\n",
      "Epoch [13/50], Train loss: 0.1890\n",
      "Early stopped training at epoch 12\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "early_stop = 5\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tot_loss = 0.0\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        #Move tensor to the configured device\n",
    "        images = sample['image'].to(device)\n",
    "        labels = sample['jointCood'].to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        tot_loss += torch.mean(loss).item()\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Garbage collection\n",
    "        del images, labels, outputs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    print(\"Epoch [{}/{}], Train loss: {:.4f}\".format(epoch+1, num_epochs, tot_loss/total_step))\n",
    "    \n",
    "    #Validation\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        total=0\n",
    "        tot_loss = 0.0\n",
    "        for i, sample in enumerate(valid_loader):\n",
    "            images = sample['image'].to(device)\n",
    "            labels = sample['jointCood'].to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            #Calculate validation loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            tot_loss += torch.mean(loss).item()\n",
    "            \n",
    "            #Garbage collection\n",
    "            del images, labels, outputs, loss\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        avg_loss = tot_loss/len(valid_loader)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), \"best_regression_model.pth\")\n",
    "        elif epoch - best_epoch > early_stop:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break\n",
    "        \n",
    "        print(\"Validation loss: {:.4f}\".format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e9ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
